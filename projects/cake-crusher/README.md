# Cake crusher
____
Данный проект позволяет токенизировать текстовый датасет, состоящий из файлов. Для токенов также проводится стемматизация и лемматизация. Результат представляется в виде tsv файлов в следующей директории: 
`assets/annotated-corpus`
## Настройка Окружения
____
Для настройки окружения и установки зависимостей требуется выполнить следующую команду из корневой директории проекта (должна быть установлена anaconda):

```
conda env create -f assets/environment.yml
conda activate cake-crusher
set PYTHONPATH=./source
```
# Запуск проекта
____
## 1. Токенизатор текстовых файлов (+ стемматизация, лемматизация)

С целью токенизации датасета требуется выполнить следующую команду из корневой директории проекта:
`python source/tokenization/__main__.py full/path/to/dataset/`

Система отображает сообщения о текущей обрабатываемой категории.
```
20news-bydate-test >>>
        alt.atheism
        comp.graphics
        comp.os.ms-windows.misc
```

### Запуск тестов токенизации
Для системы разработан набор модульных тестов, позволяющих оценить корректность генерируемых результатов. Для запуска тестов используется следующая команда, которую необходимо выполнять из корневой директории проекта:
`python source/tokenization/tests/test_tokenizer.py`

Система отображает стандартный отчет о результатах выполнения тестов:
```
.......
----------------------------------------------------------------------
Ran 9 tests in 0.005s

OK
```
____
## 2. Исправитель опечаток
Модуль использует алгоритм Левенштейна для поиска редакционного расстояния. 
Учитывается расстояние между буквами при использовании раскладки `QWERTY`.
### 2.1 Создание словаря
Чтобы создать словарь, необходимо запустить программу `dict-creator.py`.
Словарь создается на основе tsv файлов, сгенерированных модулем токенизации.
Можно сократить словарь, запустив скрипт `dict-cleaner.py`.
Результат работы:
`The dictionary has: 150015 tokens`
### 2.2 Запуск корректора
Найти и сохранить невыравненные файлы, запустив `typos-fixer/unaligned_finder.py`.
Запустить программу `typos-fixer/__main__.py`. Скорректированные токены записываются в директорию 
`assets/annotated-corpus/corrected_test` в виде tsv файлов.
### 2.3 Тестирование модуля исправления опечаток
`python source/typos_fixer/tests/typos-fixer-test.py`
### 2.4 Оценка модуля исправления опечаток
Необходимо запустить скрипт `evaluator.py`. Программа выдает отчет об исправлении опечаток:
```
Corrected files count is 296
Test tokens count is 56983
Corrupted tokens count is 9957
Corrupted tokens in corrupted set: 17.473632486882053
Corrected tokens count is 5044
Corrupted tokens in corrected set: 9.401049435796642
Difference is 8.072583051085411
```
____
## 3. N-grams
Модуль находит меру ассоциативной связности для n-грам, используя оценку t-score. По умолчанию для n = 3.

Для запуска требуется выполнить следующую команду из корневой директории проекта:
`python source/n_grams/__main__.py`

Результат представлен в виде столбчатой диаграммы для 30 триграмм, получивших наибольшую оценку.
____